/*
==============================================
# Licensed Materials - Property of IBM
# Copyright IBM Corp. 2018, 2019
==============================================
First created on: Jul/01/2018
==============================================
*/
namespace com.ibm.streamsx.sttgateway.sample.watsonstt;

use com.ibm.streamsx.sttgateway.watson::*;
/**
 * This example demonstrates transcription of audio files into text using the WatsonSTT operator. 
 * This example code is suitable for processing audio data that is already saved into 
 * a set of audio files (WAV, MP3 etc.) and made available within a specific directory.
 * 
 * This example shows how to pick up the audio files available in a given directory and
 * simply send the name of the file to the WatsonSTT operator to get the transcription results.
 * If you are looking to receive the audio data directly from the voice network switches via TCP/UDP (OR)
 * read the binary audio content from the WAV files on your own and send the
 * audio blob data (either in full or in partial blob fragments) to the WatsonSTT operator,
 * then please refer to a different example project named AudioRawWatsonSTT.
 * 
 * WAV files can be in uncompressed PCM, 16-bit little endian, 
 * 8 kHz (narrowband) or 16 KHz (broadband) sampling rate, mono format. 
 * 
 * To either downsample or upsample a WAV file, you can use the following ffmpeg command: 
 *     ffmpeg -i MyFile.wav -ac 1 -ar 8000 MyNewFile.wav
 * 
 * You can build this example from command line via the make command by using the
 * Makefile available in the top-level directory of this example. It will be
 * necessary to export the STREAMS_STTGATEWAY_TOOLKIT environment variable by
 * pointing it to the full path of your 
 * streamsx.sttgateway/com.ibm.streamsx.sttgateway directory.
 * 
 * If you want to build this example inside the Streams Studio, there are certain
 * build configuration settings needed. Please refer to the streamsx.sttgateway
 * toolkit documentation to learn more about those Streams Studio configuration settings.
 * 
 * 
 * IMPORTANT: The WatsonSTT operator uses Websocket to communicate with the 
 * Watson STT cloud service. For the STT service on IBM Public Cloud, 
 * one must use the unexpired IAM access token (generated by using your 
 * IBM Public cloud STT service instance's API key). 
 * So, user must provide here his/her API key. The operator IAMAccessTokenGenerator 
 * will use the user provided API key to generate the IAM access token and 
 * send that to the WatsonSTT operator.
 * The operator IAMAccessTokenGenerator will keep refreshing that
 * IAM access token periodically in order for it to stay unexpired.
 * You should leave this submission time value empty when not using STT on IBM public cloud.
 * https://cloud.ibm.com/docs/services/speech-to-text?topic=speech-to-text-websockets#WSopen
 * 
 * @param   sttApiKey       Specify either the public cloud IAM Token fetch/refresh URL.
 * 
 * @param   sttIAMTokenURL  Specify either the public cloud IAM Token fetch/refresh URL.
 *                          Default https://iam.cloud.ibm.com/identity/token
 * 
 * @param   sttOnCP4DAccessToken Specify the IBM STT on Cloud Pak for Data (CP4D i.e. private cloud) access token.
 *          You should leave this submission time value empty when not using STT on CP4D.
 * 
 * @param   audioDir            directory with the audio files
 * @param   numberOfSTTEngines  the number of stt engines
 * @param   sttUri              the stt service uri
 * @param   sttBaseLanguageModel   base language model; Default: en-US_NarrowbandModel
 * @param   contentType            content type; Default audio/wav
 * @param   smartFormattingNeeded  smartFormattingNeeded; Default false
 * @param   websocketLoggingNeeded websocketLoggingNeeded; Default false
 */
public composite AudioFileWatsonSTT {

	param
		expression<rstring> $sttApiKey:                      getSubmissionTimeValue("sttApiKey", "");
		expression<rstring> $sttIAMTokenURL:                 getSubmissionTimeValue("sttIAMTokenURL", "https://iam.cloud.ibm.com/identity/token");
		expression<rstring> $sttOnCP4DAccessToken:           getSubmissionTimeValue("sttOnCP4DAccessToken", "");
		expression<rstring> $audioDir:                       getSubmissionTimeValue("audioDir", "../../audio-files"); 
		expression<int32>   $numberOfSTTEngines:      (int32)getSubmissionTimeValue("numberOfSTTEngines", "5") ;
		expression<rstring> $sttUri:                         getSubmissionTimeValue("sttUri");
		expression<rstring> $sttBaseLanguageModel:           getSubmissionTimeValue("sttBaseLanguageModel", "en-US_NarrowbandModel");
		expression<rstring> $contentType:                    getSubmissionTimeValue("contentType", "audio/wav");
		expression<boolean> $smartFormattingNeeded: (boolean)getSubmissionTimeValue("smartFormattingNeeded", "false");
		expression<boolean> $websocketLoggingNeeded:(boolean)getSubmissionTimeValue("websocketLoggingNeeded", "false");

	type
		// This STT result type
		STTResult_t = int32 sequence, rstring conversationId, rstring sttErrorMessage, rstring utterance;

	graph
		// IMPORTANT: IBM STT service on public cloud requires
		// an unexpired valid IAM access token to perform the 
		// speech to text task in a secure manner. You may either 
		// provide the token in parameter sttOnCP4DAccessToken, or provide 
		// the parameter sttIAMTokenURL and sttApiKey. 
		// If you provide sttIAMTokenURL and sttApiKey, the operator IAMAccessTokenGenerator
		// generates a new access token and then periodically refreshes it. 
		// Output stream of this composite operator is connected to the
		// second input stream of the WatsonSTT operator that is used below.
		// For a correct STT operation, user must set only one of these two
		// submission time parameters to a non-empty value: sttAPIKey or sttOnCP4DAccessToken.
		stream<IAMAccessToken> IamAccessToken = IAMAccessTokenGenerator() {
			param
				apiKey: $sttApiKey;
				iamTokenURL: $sttIAMTokenURL;
				accessToken: $sttOnCP4DAccessToken;
				// All connection parameter are taken from params.
				// So if we clean the app config name, we avoid error logs
				appConfigName: "";
			config
				placement : partitionColocation("somePartitionColocationId");
		}

		// Scan a directory periodically to pick up the audio files and 
		// send the name of that audio file to the WatsonSTT operator.
		//
		// The output stream from this operator will be connected to the
		// WatsonSTT operator's input stream. That operator expects one of its
		// input stream attributes to be named as 'speech' with an SPL type of
		// either rstring or blob. That operator can take as input an 
		// audio filename (rstring) or raw binary audio data (blob).
		// In this example, we have to simply send the name of the audio file to the
		// WatsonSTT operator which will read the binary audio data on its own from that file.
		// In addition to that mandatory input stream attribute, additional
		// attributes can be sent in the input stream to be auto assigned to
		// the output stream of the WatsonSTT operator.
		stream<rstring speech, int32 sequence> AudioFileName as O = DirectoryScan() {
			logic
				state:
					mutable int32 sequence_ = 0;
			param
				directory : $audioDir;
				pattern : "\\.wav$";
				sortBy: name;
				// Give sufficient delay here so that the previous operator can complete generating the
				// IAM access token and send it to the WatsonSTT operator.
				// This is not a requirement but avoids error logs in WatsonSTT operator
				initDelay: 5.0;
			output O: sequence = sequence_++;
			config
				placement : partitionColocation("somePartitionColocationId");
		}
		
		// The WatsonSTT Operator required that each conversation end is flagged with
		// Window Punctuation.
		stream<I> AudioFileNameFlagged as O = Punctor(AudioFileName as I) {
			param
				punctuate: true;
				position: after;
			config
				placement : partitionColocation("somePartitionColocationId");
		}
		
		// Invoke one or more instances of the WatsonSTT operator.
		// Avoid feeding audio data coming from more than one data source into this 
		// parallel region which may cause erroneous transcription results.
		// NOTE: The WatsonSTT operator allows fusing multiple instances of
		// this operator into a single PE. This will help in reducing the 
		// total number of CPU cores used in running the application.
		// First input stream into this operator is the fully qualified audio file name.
		// Second input stream into this operator is your STT service instance's IAM access token.
		@parallel(width = $numberOfSTTEngines, broadcast=[AT])
		stream<STTResult_t> STTResult = 
			WatsonSTT(AudioFileNameFlagged as AFN; IamAccessToken as AT) {
			logic
				state:
					mutable int32 _conversationCnt = 0;
				
				onTuple AFN: {
					// Print the input
					printStringLn(hourMinuteSecondMillisec(getTimestamp()) + " Channel " + (rstring)getChannel() + 
						", Speech input " + (rstring)++_conversationCnt +
						": " + (rstring)AFN.speech);
				}
			param
				sttResultMode: complete;
				uri: $sttUri;
				baseLanguageModel: $sttBaseLanguageModel;
				contentType: $contentType;
				smartFormattingNeeded: $smartFormattingNeeded;
				websocketLoggingNeeded: $websocketLoggingNeeded;
			output STTResult:
				conversationId = speech,
				sttErrorMessage = getSTTErrorMessage(),
				utterance = getUtteranceText();
			config
				placement : partitionColocation("somePartitionColocationId");
		}
		
		// Print the results
		() as MySink1 = Custom(STTResult as SR) {
			logic state: mutable int32 _conversationCnt = 0;
				onTuple SR: {
					printStringLn(hourMinuteSecondMillisec(getTimestamp()) + " " + (rstring)++_conversationCnt + 
						") STT result: " + (rstring)SR);
				}
				// Window marker have no meaning in this merged stream
				// Each tuple represents an full audio transcription or one error
				onPunct SR: printStringLn(hourMinuteSecondMillisec(getTimestamp()) + (rstring)_conversationCnt + 
						") STT result: " + (rstring)currentPunct());
			config
				placement : partitionColocation("somePartitionColocationId");
		}

	config restartable: false;
} // End of composite AudioFileWatsonSTT (Main composite)
