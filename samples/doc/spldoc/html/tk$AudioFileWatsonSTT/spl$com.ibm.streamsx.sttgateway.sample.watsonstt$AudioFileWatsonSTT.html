<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xml:lang="en-us" lang="en-us">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta name="copyright" content="(C) Copyright 2005"/>
<meta name="DC.rights.owner" content="(C) Copyright 2005"/>
<meta name="DC.Type" content="reference"/>
<meta name="DC.Title" content="SPL File AudioFileWatsonSTT.spl"/>
<meta name="DC.Format" content="XHTML"/>
<meta name="DC.Identifier" content="spldoc_compilationunit"/>
<link rel="stylesheet" type="text/css" href="../../html/commonltr.css"/>
<link rel="stylesheet" type="text/css" href="../../html/spldoc.css"/>
<title>SPL File AudioFileWatsonSTT.spl</title>
</head>
<body id="spldoc_compilationunit">


<h1 class="title topictitle1">SPL File <tt class="ph tt">AudioFileWatsonSTT.spl</tt></h1>

<div class="body refbody">
<div class="section">
<p class="p">
<a class="xref" href="../toolkits/toolkits.html">Gateway to the IBM Speech To Text (STT) cloud service samples</a> &gt; <a class="xref" href="tk$AudioFileWatsonSTT.html">AudioFileWatsonSTT 1.0.6</a> &gt; <a class="xref" href="ns$com.ibm.streamsx.sttgateway.sample.watsonstt.html">com.ibm.streamsx.sttgateway.sample.watsonstt</a> &gt; AudioFileWatsonSTT.spl</p>

</div>

<div class="section"><h2 class="title sectiontitle splhead-1">Content</h2>
  
  <dl class="dl">
    <dt class="dt dlterm"/>
<dd class="dd"/>

    
      <dt class="dt dlterm splhead-2">Operators</dt>

      <dd class="dd">
<ul class="sl simple">
<li class="sli"><strong class="ph b"><a class="xref" href="spl$com.ibm.streamsx.sttgateway.sample.watsonstt$AudioFileWatsonSTT.html#spldoc_compilationunit__composite_operator__AudioFileWatsonSTT">AudioFileWatsonSTT</a></strong>: This example demonstrates transcription of audio files into text using the WatsonSTT operator.
</li>

</ul>

      </dd>

    
  </dl>

</div>

<div class="section"><h2 class="title sectiontitle splhead-1">Composites</h2>
  
</div>

<div class="section" id="spldoc_compilationunit__composite_operator__AudioFileWatsonSTT"><h2 class="title sectiontitle splpart">composite AudioFileWatsonSTT</h2>
  
</div>

<div class="section splgraph">
  <embed class="image" src="../../image/tk$AudioFileWatsonSTT/op$com.ibm.streamsx.sttgateway.sample.watsonstt$AudioFileWatsonSTT.svg" width="547" height="154"/>
</div>

<div class="section">

<p class="p">This example demonstrates transcription of audio files into text using the WatsonSTT operator.  This example code is suitable for processing audio data that is already saved into  a set of audio files (WAV, MP3 etc.) and made available within a specific directory.
</p>

<p class="p">This example shows how to pick up the audio files available in a given directory and simply send the name of the file to the WatsonSTT operator to get the transcription results. If you are looking to receive the audio data directly from the voice network switches via TCP/UDP (OR) read the binary audio content from the WAV files on your own and send the audio blob data (either in full or in partial blob fragments) to the WatsonSTT operator, then please refer to a different example project named AudioRawWatsonSTT.
</p>

<p class="p">WAV files can be in uncompressed PCM, 16-bit little endian,  8 kHz (narrowband) or 16 KHz (broadband) sampling rate, mono format. 
</p>

<div class="p">To either downsample or upsample a WAV file, you can use the following ffmpeg command: 
<pre class="pre codeblock">
ffmpeg -i MyFile.wav -ac 1 -ar 8000 MyNewFile.wav
</pre>


</div>

<p class="p">You can build this example from command line via the make command by using the Makefile available in the top-level directory of this example. It will be necessary to export the STREAMS_STTGATEWAY_TOOLKIT environment variable by pointing it to the full path of your  streamsx.sttgateway/com.ibm.streamsx.sttgateway directory.
</p>

<p class="p">If you want to build this example inside the Streams Studio, there are certain build configuration settings needed. Please refer to the streamsx.sttgateway toolkit documentation to learn more about those Streams Studio configuration settings.
</p>

<p class="p">IMPORTANT: The WatsonSTT operator uses Websocket to communicate with the  Watson STT cloud service. For the STT service on IBM Public Cloud,  one must use the unexpired IAM access token (generated by using your  IBM Public cloud STT service instance's API key).  So, user must provide here his/her API key.  The operator IAMAccessTokenGenerator will use the user provided API key to generate the IAM access token and  send that to the WatsonSTT operator. The operator IAMAccessTokenGenerator will keep refreshing that  IAM access token periodically in order for it to stay unexpired.  Alternatively you can provide the access token directly. In this case the access token is send directly to Watson STT  cloud service and no refreshing logic is invoked. See: https://cloud.ibm.com/docs/services/speech-to-text?topic=speech-to-text-websockets#WSopen
</p>

<p class="p">The sample is designed to receive all connection related parameters from <em class="ph i">application configuration</em> with name  <em class="ph i">sttConnection</em>. This application configuration must contain the following properties:
</p>

<div class="p">
<pre class="pre codeblock">
* apiKey: IBM Public cloud STT service instance's API key Specify either the apiKey or
* accessToken: access token (e. g. Specify the IBM STT on Cloud Pak for Data access token) This property is required if apiKey is used.
* iamTokenURL: The service url of the IAM Token authorization service to fetch and refresh the IAM access
* url:         The websocket url of your stt service instance
</pre>


</div>

<p class="p">A sample for an stt url: wss://api.us-south.speech-to-text.watson.cloud.ibm.com/instances/4833f0f6-d2b3-4ee0-bc35-ecaf21eabcdef/v1/recognize
</p>

<div class="p">To create the application configuration enter the following commands:
<pre class="pre codeblock">
	streamtool mkappconfig --description 'connection configuration for IBM Cloud Watson stt service' \
		--property "apiKey=&lt;your api key&gt;" \
		--property "iamTokenURL=https://iam.cloud.ibm.com/identity/token" \
		--property "url=&lt;your stt instance uri&gt; \
		"sttConnection"
</pre>


</div>

<p class="p">NOTE: You may use the scripts start and stop to stop the sample
</p>

</div>

<div class="section"><h2 class="title sectiontitle">Parameters</h2>

<ul class="sl simple">
<li class="sli"><strong class="ph b">appConfigName</strong>: The name of the application configuration to look for connection parameters. Default is <em class="ph i">sttConnection</em> 
</li>

<li class="sli"><strong class="ph b">audioDir</strong>: directory with the audio files 
</li>

<li class="sli"><strong class="ph b">baseLanguageModel</strong>: base language model; Default: en-US_NarrowbandModel 
</li>

<li class="sli"><strong class="ph b">contentType</strong>: content type; Default audio/wav 
</li>

<li class="sli"><strong class="ph b">nonFinalUtterancesNeeded</strong>: nonFinalUtterancesNeeded; Default false
</li>

</ul>

</div>

<div class="section">
</div>

<div class="section">
</div>

<div class="section"><h2 class="title sectiontitle splhead-2">SPL Source Code</h2>
  
</div>


<div class="section">
   <pre class="pre codeblock">

 public composite AudioFileWatsonSTT {
 
 	param
 		expression&lt;rstring&gt; $appConfigName:                  getSubmissionTimeValue("appConfigName", "sttConnection");
 		expression&lt;rstring&gt; $audioDir:                       getSubmissionTimeValue("audioDir", "../../audio-files"); 
 		expression&lt;rstring&gt; $baseLanguageModel:              getSubmissionTimeValue("baseLanguageModel", "en-US_NarrowbandModel");
 		expression&lt;rstring&gt; $contentType:                    getSubmissionTimeValue("contentType", "audio/wav");
 		expression&lt;boolean&gt; $nonFinalUtterancesNeeded: (boolean)getSubmissionTimeValue("nonFinalUtterancesNeeded", "false");
 
 	type
 		STTResult = tuple&lt;uint64 myseq&gt;, STTResult_t;
 	
 	graph
 
 		// Scan a directory periodically to pick up the audio files and 
 		// send the name of that audio file to the WatsonSTT operator.
 		//
 		// The output stream from this operator will be connected to the
 		// WatsonSTT operator's input stream. That operator expects one of its
 		// input stream attributes to be named as 'speech' with an SPL type of
 		// either rstring or blob. That operator can take as input an 
 		// audio filename (rstring) or raw binary audio data (blob).
 		// In this example, we have to simply send the name of the audio file to the
 		// WatsonSTT operator which will read the binary audio data on its own from that file.
 		// In addition to that mandatory input stream attribute, additional
 		// attributes can be sent in the input stream to be auto assigned to
 		// the output stream of the WatsonSTT operator.
 		stream&lt;rstring speech, uint64 myseq&gt; FileNameStream as O = DirectoryScan() {
 			logic
 				state:
 					mutable uint64 sequence_ = 0;
 			param
 				directory : $audioDir;
 				pattern : "\\.wav$";
 				sortBy: name;
 				// Give sufficient delay here so that the previous operator can complete generating the
 				// IAM access token and send it to the WatsonSTT operator.
 				// This is not a requirement but avoids error logs in WatsonSTT operator
 				initDelay: 5.0;
 			output O:
 				myseq = sequence_++;
 			config
 				placement : partitionColocation("somePartitionColocationId");
 		}
 		
 		// The WatsonSTT Operator required that each conversation end is flagged with
 		// Window Punctuation.
 		stream&lt;I&gt; FlaggedFileNameStream = Punctor(FileNameStream as I) {
 			param
 				punctuate: true;
 				position: after;
 			config
 				placement : partitionColocation("somePartitionColocationId");
 		}
 		
 		// Provide the second input stream with the access token and refresh the token
 		// periodically if required
 		stream&lt;IAMAccessToken&gt; IAMAccessTokenStream = IAMAccessTokenGenerator() {
 			config
 				placement : partitionColocation("somePartitionColocationId");
 		}
 
 		// Invoke one instance of the WatsonSTT operator.
 		// First input stream into this operator is the fully qualified audio file name.
 		// Second input stream into this operator is your STT service instance's IAM access token.
 		stream&lt;STTResult&gt; STTResultStream as O = WatsonSTT(FlaggedFileNameStream; IAMAccessTokenStream) {
 			param
 				uri: getApplicationConfigurationProperty($appConfigName, "url", "");
 				baseLanguageModel: $baseLanguageModel;
 				contentType: $contentType;
 				sttResultMode: partial;
 				nonFinalUtterancesNeeded: $nonFinalUtterancesNeeded;
 			output O:
 				conversationId = speech;
 			config
 				placement : partitionColocation("somePartitionColocationId");
 		}
 
 		// Make some formatting of the output
 		stream&lt;rstring line&gt; PrintStream as O = Custom(STTResultStream as I) {
 			logic
 				onTuple I: {
 					mutable O otuple = {};
 					if (sttErrorMessage == "") {
 						if (transcriptionCompleted) {
 						otuple.line = "conversationId=" + conversationId + " myseq=" + (rstring)myseq + "\n" +
 							"*** Conversation complete ***\n";
 						} else {
 							otuple.line = "conversationId=" + conversationId + " myseq=" + (rstring)myseq + "\n" +
 								"finalizedUtterance=" + (rstring)finalizedUtterance + " utteranceNumber=" + (rstring)utteranceNumber +
 								" confidence=" + (rstring)confidence + " utteranceStartTime=" + (rstring)utteranceStartTime +
 								" utteranceEndTime=" + (rstring)utteranceEndTime + "\n" +
 								utteranceText + "\n";
 							}
 					} else {
 						otuple.line = "conversationId=" + conversationId + " myseq=" + (rstring)myseq + "\n" +
 							"transcriptionCompleted=" + (rstring)transcriptionCompleted +
 							" finalizedUtterance=" + (rstring)finalizedUtterance + "\n" +
 							"    *** ERROR *** " + sttErrorMessage + "\n";
 					}
 					submit(otuple, O);
 				}
 			config
 				placement : partitionColocation("somePartitionColocationId");
 		}
 		
 		() as Sink = FileSink(PrintStream) {
 			param
 				file: "Tuples";
 				append: true;
 				flush: 1u;
 				format: FileSink.line;
 			config
 				placement : partitionColocation("somePartitionColocationId");
 		}
 
 	config restartable: false;
 } // End of composite AudioFileWatsonSTT (Main composite)

   </pre>

</div>

</div>


</body>
</html>