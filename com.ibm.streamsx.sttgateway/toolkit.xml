<?xml version="1.0" encoding="UTF-8" standalone="no" ?>
<toolkitModel xmlns="http://www.ibm.com/xmlns/prod/streams/spl/toolkit" productVersion="4.2.1.6" xmlns:common="http://www.ibm.com/xmlns/prod/streams/spl/common" xmlns:ti="http://www.ibm.com/xmlns/prod/streams/spl/toolkitInfo" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">

  <toolkit name="com.ibm.streamsx.sttgateway" requiredProductVersion="4.2.1.6" version="1.0.5">
    <description/>
    <uriTable>
      <uri index="8" value="com.ibm.streamsx.sttgateway.watson/IBMVoiceGatewaySource/ibmvgwsource_32.gif"/>
      <uri index="7" value="com.ibm.streamsx.sttgateway.watson/IBMVoiceGatewaySource/ibmvgwsource_16.gif"/>
      <uri index="1" value="com.ibm.streamsx.sttgateway.watson/IAMAccessTokenGenerator.spl"/>
      <uri index="2" value="com.ibm.streamsx.sttgateway.watson/native.function/function.xml"/>
      <uri index="5" value="com.ibm.streamsx.sttgateway.watson/WatsonSTT/watsonstt_32.gif"/>
      <uri index="6" value="com.ibm.streamsx.sttgateway.watson/IBMVoiceGatewaySource"/>
      <uri index="3" value="com.ibm.streamsx.sttgateway.watson/WatsonSTT"/>
      <uri index="4" value="com.ibm.streamsx.sttgateway.watson/WatsonSTT/watsonstt_16.gif"/>
    </uriTable>
    <namespace name="com.ibm.streamsx.sttgateway.watson">
      <primitiveOp language="Cpp" modelUriIndex="3" name="WatsonSTT" public="true">
        <description>
      The WatsonSTT operator is designed to ingest audio data in the form of a file (.wav, .mp3 etc.)
      or RAW audio and then transcribe that audio into text via the 
      IBM Watson STT (Speech To Text) cloud service. It does that by sending the audio data 
      to the configured Watson STT service running in the IBM public cloud or in the 
      IBM Cloud Pak for Data (CP4D) via the Websocket interface. It then outputs transcriptions of 
      speech in the form of utterances or in full text as configured. An utterance is a 
      group of transcribed words meant to approximate a sentence. Audio data must be in 16-bit 
      little endian, mono format. For the Telephony model and configurations, the audio must 
      have an 8 kHz sampling rate. For the Broadband model and configurations, the audio must 
      have a 16 kHz sampling rate. The data can be provided as a .wav file or as 
      RAW uncompressed PCM audio. Here is a sample ffmpeg command to convert a .wav file 
      to the correct telephony format (use -ar 16000 for broadband): 
      
      \$ ffmpeg -i MyFile.wav -ac 1 -ar 8000 MyNewFile.wav
      
      This operator must be configured with a Websocket URL, a Watson STT authentication token and
      a base language model (see in parameter section).
      This operator may also be customized with many other optional parameters including 
      custom patch files and appropriate custom patch weights.
      
      Requirements: 
      * Intel RHEL6 or RHEL7 hosts installed with IBM Streams. 
      
      **Note:** Multiple invocations of this operator can be fused to make 
      an efficient use of the available pool of CPU cores.
      
      See the samples folder inside this toolkit for working examples that show how to use this operator.
      
      For a detailed documentation about the operator design, usage patterns and in-depth technical
      details, please refer to the official STT Gateway toolkit documentation available at this URL:
      
      [https://ibmstreams.github.io/streamsx.sttgateway]
      </description>
        <images>
          <image size="16" uriIndex="4"/>
          <image size="32" uriIndex="5"/>
        </images>
        <outputFunctions name="STTGatewayFunctions">
          <function name="AsIs" returnType="T">
            <description>The default function for output attributes. This function assigns the output attribute to the value of the input attribute with the same name.</description>
            <prototype>&lt;any T&gt; T AsIs(T)</prototype>
            <parameter name="__p1" type="T"/>
          </function>
          <function name="getUtteranceNumber" returnType="int32">
            <description>Returns an int32 number indicating the utterance number.</description>
            <prototype>int32 getUtteranceNumber()</prototype>
          </function>
          <function name="getUtteranceText" returnType="rstring">
            <description>Returns the transcription of audio in the form of a single utterance.</description>
            <prototype>rstring getUtteranceText()</prototype>
          </function>
          <function name="isFinalizedUtterance" returnType="boolean">
            <description>Returns a boolean value to indicate if this is an interim partial utterance or a finalized utterance.</description>
            <prototype>boolean isFinalizedUtterance()</prototype>
          </function>
          <function name="getConfidence" returnType="float32">
            <description>Returns a float32 confidence value for an interim partial utterance or for a finalized utterance or for the full text.</description>
            <prototype>float32 getConfidence()</prototype>
          </function>
          <function name="getFullTranscriptionText" returnType="rstring">
            <description>Returns the transcription of audio in the form of full text after completing the entire transcription.</description>
            <prototype>rstring getFullTranscriptionText()</prototype>
          </function>
          <function name="getSTTErrorMessage" returnType="rstring">
            <description>Returns the Watson STT error message if any.</description>
            <prototype>rstring getSTTErrorMessage()</prototype>
          </function>
          <function name="isTranscriptionCompleted" returnType="boolean">
            <description>Returns a boolean value to indicate whether the full transcription is completed.</description>
            <prototype>boolean isTranscriptionCompleted()</prototype>
          </function>
          <function name="getUtteranceAlternatives" returnType="list&lt;rstring>">
            <description>Returns a list of n-best alternative hypotheses for an utterance result. List will have the very best guess first followed by the next best ones in that order.</description>
            <prototype>list&lt;rstring&gt; getUtteranceAlternatives()</prototype>
          </function>
          <function name="getWordAlternatives" returnType="list&lt;list&lt;rstring>>">
            <description>Returns a nested list of word alternatives (Confusion Networks).</description>
            <prototype>list&lt;list&lt;rstring&gt;&gt; getWordAlternatives()</prototype>
          </function>
          <function name="getWordAlternativesConfidences" returnType="list&lt;list&lt;float64>>">
            <description>Returns a nested list of word alternatives confidences (Confusion Networks).</description>
            <prototype>list&lt;list&lt;float64&gt;&gt; getWordAlternativesConfidences()</prototype>
          </function>
          <function name="getWordAlternativesStartTimes" returnType="list&lt;float64>">
            <description>Returns a list of word alternatives start times (Confusion Networks).</description>
            <prototype>list&lt;float64&gt; getWordAlternativesStartTimes()</prototype>
          </function>
          <function name="getWordAlternativesEndTimes" returnType="list&lt;float64>">
            <description>Returns a list of word alternatives end times (Confusion Networks).</description>
            <prototype>list&lt;float64&gt; getWordAlternativesEndTimes()</prototype>
          </function>
          <function name="getUtteranceWords" returnType="list&lt;rstring>">
            <description>Returns a list of words in an utterance result.</description>
            <prototype>list&lt;rstring&gt; getUtteranceWords()</prototype>
          </function>
          <function name="getUtteranceWordsConfidences" returnType="list&lt;float64>">
            <description>Returns a list of confidences of the words in an utterance result.</description>
            <prototype>list&lt;float64&gt; getUtteranceWordsConfidences()</prototype>
          </function>
          <function name="getUtteranceWordsStartTimes" returnType="list&lt;float64>">
            <description>Returns a list of start times of the words in an utterance result relative to the start of the audio.</description>
            <prototype>list&lt;float64&gt; getUtteranceWordsStartTimes()</prototype>
          </function>
          <function name="getUtteranceWordsEndTimes" returnType="list&lt;float64>">
            <description>Returns a list of end times of the words in an utterance result relative to the start of the audio.</description>
            <prototype>list&lt;float64&gt; getUtteranceWordsEndTimes()</prototype>
          </function>
          <function name="getUtteranceStartTime" returnType="float64">
            <description>Returns the start time of an utterance relative to the start of the audio.</description>
            <prototype>float64 getUtteranceStartTime()</prototype>
          </function>
          <function name="getUtteranceEndTime" returnType="float64">
            <description>Returns the end time of an utterance relative to the start of the audio.</description>
            <prototype>float64 getUtteranceEndTime()</prototype>
          </function>
          <function name="getUtteranceWordsSpeakers" returnType="list&lt;int32>">
            <description>Returns a list of speaker ids for the individual words in an utterance result.</description>
            <prototype>list&lt;int32&gt; getUtteranceWordsSpeakers()</prototype>
          </function>
          <function name="getUtteranceWordsSpeakersConfidences" returnType="list&lt;float64>">
            <description>Returns a list of confidences in identifying the speakers of the individual words in an utterance result.</description>
            <prototype>list&lt;float64&gt; getUtteranceWordsSpeakersConfidences()</prototype>
          </function>
          <function name="getKeywordsSpottingResults" returnType="map&lt;rstring, list&lt;map&lt;rstring, float64>>>">
            <description>Returns the STT keywords spotting results as a map of key/value pairs. Read this toolkit's documentation to learn about the map contents.</description>
            <prototype>map&lt;rstring, list&lt;map&lt;rstring, float64&gt;&gt;&gt; getKeywordsSpottingResults()</prototype>
          </function>
        </outputFunctions>
        <parameter cardinality="1" expressionMode="AttributeFree" name="uri" optional="false" type="rstring">
          <description>This parameter specifies the Watson STT Websocket service URI.</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="baseLanguageModel" optional="false" type="rstring">
          <description>This parameter specifies the name of the Watson STT base language model that should be used.</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="contentType" optional="true" type="rstring">
          <description>This parameter specifies the content type to be used for transcription. (Default is audio/wav)</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="sttResultMode" optional="true" type="int32">
          <description>This parameter specifies what type of STT result is needed: 1 to get partial utterances, 2 to get completed utterance, 3 (default) to get the full text after transcribing the entire audio.</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="sttRequestLogging" optional="true" type="boolean">
          <description>This parameter specifies whether request logging should be done for every STT audio transcription request. (Default is false)</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="baseModelVersion" optional="true" type="rstring">
          <description>This parameter specifies a particular base model version to be used for transcription. (Default is an empty string)</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="customizationId" optional="true" type="rstring">
          <description>This parameter specifies a custom language model to be used for transcription. (Default is an empty string)</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="customizationWeight" optional="true" type="float64">
          <description>This parameter specifies a relative weight for a custom language model as a float64 between 0.0 to 1.0 (Default is 0.0)</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="acousticCustomizationId" optional="true" type="rstring">
          <description>This parameter specifies a custom acoustic model to be used for transcription. (Default is an empty string)</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="filterProfanity" optional="true" type="boolean">
          <description>This parameter indicates whether profanity should be filtered from a transcript. (Default is false)</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="sttJsonResponseDebugging" optional="true" type="boolean">
          <description>This parameter is used for debugging the STT JSON response message. Mostly for IBM internal use. (Default is false)</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="maxUtteranceAlternatives" optional="true" type="int32">
          <description>This parameter indicates the required number of n-best alternative hypotheses for the transcription results. (Default is 1)</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="wordAlternativesThreshold" optional="true" type="float64">
          <description>This parameter controls the density of the word alternatives results (a.k.a. Confusion Networks). A value of 0.0 disables this feature. Valid value must be less than 1.0 (Default is 0.0)</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="wordConfidenceNeeded" optional="true" type="boolean">
          <description>This parameter indicates whether the transcription result should include individual words and their confidences or not. (Default is false)</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="wordTimestampNeeded" optional="true" type="boolean">
          <description>This parameter indicates whether the transcription result should include individual words and their timestamps or not. (Default is false)</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="identifySpeakers" optional="true" type="boolean">
          <description>This parameter indicates whether the speakers of the individual words in an utterance result should be identified. (Default is false)</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="smartFormattingNeeded" optional="true" type="boolean">
          <description>This parameter indicates whether to convert date, time, phone numbers, currency values, email and URLs into conventional representations. (Default is false)</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="keywordsSpottingThreshold" optional="true" type="float64">
          <description>This parameter specifies the minimum confidence level that the STT service must have for an utterance word to match a given keyword. A value of 0.0 disables this feature. Valid value must be less than 1.0. (Default is 0.0)</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="keywordsToBeSpotted" optional="true" type="list&lt;rstring>">
          <description>This parameter specifies a list (array) of strings to be spotted. (Default is an empty list)</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="websocketLoggingNeeded" optional="true" type="boolean">
          <description>This parameter specifies whether logging is needed from the Websocket library. (Default is false)</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="cpuYieldTimeInAudioSenderThread" optional="true" type="float64">
          <description>This parameter specifies the CPU yield time (in seconds) needed inside the audio sender thread's tight loop spinning to look for new audio data to be sent to the STT service. It should be &gt;= 0.0 (Default is 0.001 i.e. 1 millisecond)</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="waitTimeBeforeSTTServiceConnectionRetry" optional="true" type="float64">
          <description>This parameter specifies the time (in seconds) to wait before retrying a connection attempt to the Watson STT service. It should be &gt;= 1.0 (Default is 3.0)</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="maxAllowedConnectionAttempts" optional="true" type="int32">
          <description>This parameter specifies the maximum number of attempts to make a Websocket connection to the STT service. It should be &gt;= 1 (Default is 10)</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="sttLiveMetricsUpdateNeeded" optional="true" type="boolean">
          <description>This parameter specifies whether live update for this operator's custom metrics is needed. (Default is true)</description>
        </parameter>
        <inputPort maxNumPorts="1" minNumPorts="1" optional="false" windowPunctInputMode="Oblivious">
          <description>
      	This port brings the audio data into this operator for transcription.
      	
      	Attributes on this input port:
		* **speech** (required, rstring/blob) - In the case of file based input (.wav, .mp3 etc. for batch workload), the expected value will be an absolute path of a file as an rstring. In the case of RAW audio data (received from a network switch for real-time workload), the expected input is of type blob.
		* **conversationId** (optional, rstring) - An rstring conversationId field for identifying the origin of the audio data that is being sent for transcription (either an audio filename or a call center specific call identifier).
        
		All the extra input attributes will be forwarded if matching output attributes are found.  	
      	</description>
          <windowPolicy>NonWindowed</windowPolicy>
        </inputPort>
        <inputPort maxNumPorts="1" minNumPorts="1" optional="false" windowPunctInputMode="Oblivious">
          <description>
      	This port brings an unexpired IAM access token (generated by using your 
        service instance's API key) into this operator that is needed to access the Watson STT service.
      	
      	Attributes on this input port:
		* **access_token** (required, rstring) - An rstring access token required for securing the access to the STT service.
        
		All the extra attributes found in this input port will be ignored.  	
      	</description>
          <windowPolicy>NonWindowed</windowPolicy>
        </inputPort>
        <outputPort expressionMode="Expression" maxNumPorts="1" minNumPorts="1" optional="false" windowPunctOutputMode="Preserving">
          <description>
      	This port produces the output tuples that carry the result of the speech to text transcription.
      	
        An output tuple is created for every utterance that is observed from the incoming audio data. 
        An utterance is a group of transcribed words meant to approximate a sentence. 
        This means there is a one to many relationship between an incoming tuple and outgoing tuples 
        (i.e. a single .wav file may result in 30 output utterances).
        Intermediate utterances are sent out on this output port only when the sttResultMode
        operator parameter is set to a value of either 1 or 2. If it is set to 3, then only the
        fully transcribed text for the entire audio data will be sent on this output port after
        the given audio is completely transcribed. 
        **There are multiple available output functions**, and output attributes can also be 
        assigned values with any SPL expression that evaluates to the proper type.      	
      	</description>
        </outputPort>
      </primitiveOp>
      <primitiveOp language="Cpp" modelUriIndex="6" name="IBMVoiceGatewaySource" public="true">
        <description>
      The IBMVoiceGatewaySource operator is designed to ingest 
      speech data from the IBM Voice Gateway product version 1.0.3.0 or above. 
      This speech data is ingested in binary format from the 
      IBM Voice Gateway into this operator via the Websocket interface. 
      Such speech data arrives here in multiple fragments directly from 
      a live voice call. This operator is capable of receiving speech data 
      from multiple calls that can all happen at the very same time 
      between different pairs of speakers. For every voice call it handles 
      in real-time, the IBM Voice Gateway product will open two 
      Websocket connections into this operator and start sending the 
      live speech data on both of those connections. One of those connections 
      will carry the speech data of the agent and the other connection 
      will carry the speech data of the customer. This operator will 
      keep sending the audio chunks received on those two Websocket 
      connections via its output stream for consumption by the 
      downstream operators. At the end of the any given call, 
      IBM Voice Gateway will close the two WebSocket connections it 
      opened into this operator.
            
      This operator can be configured with a Websocket port number which is optional. If the user of this
      operator doesn't specify a Websocket port number, then a default port number of 443 will be used.
      
      Requirements: 
      * Intel RHEL6 or RHEL7 hosts installed with IBM Streams. 
      
      See the samples folder inside this toolkit for a working example that show how to use this operator.
      
      For a detailed documentation about the operator design, usage patterns and in-depth technical
      details, please refer to the official STT Gateway toolkit documentation available at this URL:
      
      [https://ibmstreams.github.io/streamsx.sttgateway]
      </description>
        <images>
          <image size="16" uriIndex="7"/>
          <image size="32" uriIndex="8"/>
        </images>
        <outputFunctions name="IBMVoiceGatewaySourceFunctions">
          <function name="AsIs" returnType="T">
            <description>The default function for output attributes. This function assigns the output attribute to the value of the input attribute with the same name.</description>
            <prototype>&lt;any T&gt; T AsIs(T)</prototype>
            <parameter name="__p1" type="T"/>
          </function>
          <function name="getIBMVoiceGatewaySessionId" returnType="rstring">
            <description>Returns an rstring value indicating the IBM Voice Gateway session id that corresponds to the current output tuple.</description>
            <prototype>rstring getIBMVoiceGatewaySessionId()</prototype>
          </function>
          <function name="isCustomerSpeechData" returnType="boolean">
            <description>Returns a boolean value to indicate if this is a customer's speech data or not.</description>
            <prototype>boolean isCustomerSpeechData()</prototype>
          </function>
          <function name="getTupleCnt" returnType="int32">
            <description>Returns an int32 value indicating the total number of output tuples emitted so far for the given channel in a IBM Voice Gateway session id.</description>
            <prototype>int32 getTupleCnt()</prototype>
          </function>
          <function name="getTotalSpeechDataBytesReceived" returnType="int32">
            <description>Returns an int32 value indicating the total number of speech data bytes received so far for the given channel in a IBM Voice Gateway session id.</description>
            <prototype>int32 getTotalSpeechDataBytesReceived()</prototype>
          </function>
          <function name="getVoiceChannelNumber" returnType="int32">
            <description>Returns an int32 value indicating the voice channel number in which the speech data bytes were received for a IBM Voice Gateway session id.</description>
            <prototype>int32 getVoiceChannelNumber()</prototype>
          </function>
          <function name="getAgentPhoneNumber" returnType="rstring">
            <description>Returns an rstring value with details about the agent's phone number.</description>
            <prototype>rstring getAgentPhoneNumber()</prototype>
          </function>
          <function name="getCallerPhoneNumber" returnType="rstring">
            <description>Returns an rstring value with details about the caller's phone number.</description>
            <prototype>rstring getCallerPhoneNumber()</prototype>
          </function>
        </outputFunctions>
        <parameter cardinality="1" expressionMode="AttributeFree" name="tlsPort" optional="true" type="uint32">
          <description>This parameter specifies the WebSocket TLS port number. Default port number is 443.</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="certificateFileName" optional="true" type="rstring">
          <description>This parameter specifies the WebSocket server PEM certificate file name. Default is to read ws-server.pem from the etc sub-directory of the application.</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="nonTlsEndpointNeeded" optional="true" type="boolean">
          <description>This parameter specifies whether a WebSocket (plain) non-TLS endpoint is needed. (Default is false)</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="nonTlsPort" optional="true" type="uint32">
          <description>This parameter specifies the WebSocket (plain) non-TLS port number. Default port number is 80.</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="initDelay" optional="true" type="float64">
          <description>This parameter specifies a one time delay in seconds for which this source operator should wait before start generating its first tuple.</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="vgwLiveMetricsUpdateNeeded" optional="true" type="boolean">
          <description>This parameter specifies whether live update for this operator's custom metrics is needed. (Default is true)</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="websocketLoggingNeeded" optional="true" type="boolean">
          <description>This parameter specifies whether logging is needed from the WebSocket library. (Default is false)</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="vgwSessionLoggingNedded" optional="true" type="boolean">
          <description>This parameter specifies whether logging is needed when the IBM Voice Gateway session is in progress with this operator. (Default is false)</description>
        </parameter>
        <parameter cardinality="1" expressionMode="AttributeFree" name="vgwStaleSessionPurgeInterval" optional="true" type="uint32">
          <description>This parameter specifies time interval in seconds during which any stale Voice Gateway sessions should be purged to free up memory usage. (Default is 3*60*60 seconds)</description>
        </parameter>
        <outputPort expressionMode="Expression" maxNumPorts="1" minNumPorts="1" optional="false" windowPunctOutputMode="Free">
          <description>
      	This port produces the output tuples that carry the binary speech data received from 
      	the IBM Voice Gateway. The schema for this port must have its first attribute named 
      	as speech with a blob data type to hold the speech data. Remaining attributes can be 
      	of any type based on the needs of the application. Such speech data being sent in 
      	these output tuples can represent multiple fragments of a full conversation 
      	happening in a live voice call. This operator is capable of sending out speech data
		from multiple calls that can all happen at the very same time between different 
		pairs of speakers. IBM Voice Gateway will always send the speech data in two voice
		channels i.e. one channel will carry the speech data of a customer and the other
		channel will carry the speech data of an agent. Please refer to the custom 
		output functions provided by this operator to query such voice call meta data
		information and assign that meta data values to other optional attributes in this
		output port. 
      	
        **There are multiple available output functions**, and output attributes can also be 
        assigned values with any SPL expression that evaluates to the proper type.      	
      	</description>
        </outputPort>
        <outputPort expressionMode="Expression" maxNumPorts="1" minNumPorts="1" optional="false" windowPunctOutputMode="Free">
          <description>
      	This port produces periodic output tuples to give an indication about the end of a 
      	specific speaker (i.e. channel) in a voice call that was in progress moments ago for 
      	the given IBM Voice Gateway session id. The schema for this port must have these 
      	three attributes with their correct data types as shown here. 
      	rstring vgwSessionId, boolean isCustomerSpeechData, int32 vgwVoiceChannelNumber
      	This source operator will set the appropriate values for these attributes to 
      	indicate which particular speaker (i.e. voice channel number) of a given voice call 
      	(i.e. session id) just ended the conversation. This tuple also has an attribute 
      	(i.e. isCustomerSpeechData) to tell whether that recently ended voice channel
      	carried the speech data of a customer or an agent. Downstream operators can make 
      	use of this "End Of Voice Call" signal as they see fit.
      	</description>
        </outputPort>
      </primitiveOp>
      <compositeOp column="18" line="39" name="IAMAccessTokenGenerator" potentialMain="false" public="true" uriIndex="1">
        <parameter metaType="Expression" name="sttApiKey" optional="false" type="&lt;rstring>"/>
        <parameter metaType="Expression" name="sttIAMTokenURL" optional="false" type="&lt;rstring>"/>
        <parameter metaType="Expression" name="sttAccessTokenRefreshInterval" optional="false" type="&lt;float64>"/>
        <parameter metaType="Expression" name="initDelay" optional="false" type="&lt;float64>"/>
        <outputPort name="IamAccessToken" portIndex="0"/>
      </compositeOp>
      <function modelUriIndex="2" name="launch_app" native="true" public="true" returnType="int32" uriIndex="0">
        <description>It launches any command or utility or application.</description>
        <prototype>public int32 launch_app(rstring appName, mutable rstring resultStringOutput)</prototype>
        <parameter name="appName" type="rstring"/>
        <parameter mutable="true" name="resultStringOutput" type="rstring"/>
      </function>
      <type column="6" line="36" name="IamAccessToken_t" static="true" type="rstring access_token, rstring refresh_token, rstring scope, int64 expiration, rstring token_type, int64 expires_in" uriIndex="1"/>
    </namespace>
    <dependency>
      <common:name>com.ibm.streamsx.json</common:name>
      <common:version>[1.4.6,2.0.0)</common:version>
    </dependency>
    <sabFiles>
      <ti:include path="toolkit.xml" root="toolkitDir"/>
      <ti:include path="impl/java/lib/**" root="toolkitDir"/>
      <ti:include path="impl/java/bin/**" root="toolkitDir"/>
      <ti:include path="impl/bin/**" root="toolkitDir"/>
      <ti:include path="impl/lib/**" root="toolkitDir"/>
      <ti:include path="impl/nl/*.dat" root="toolkitDir"/>
      <ti:include path="etc/**" root="toolkitDir"/>
      <ti:include path="lib/**" root="toolkitDir"/>
      <ti:include path="nl/**" root="toolkitDir"/>
      <ti:include path="opt/**" root="toolkitDir"/>
    </sabFiles>
  </toolkit>

</toolkitModel>
