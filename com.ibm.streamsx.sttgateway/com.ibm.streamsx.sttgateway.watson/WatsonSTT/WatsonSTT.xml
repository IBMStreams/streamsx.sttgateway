<?xml version="1.0" ?>
<operatorModel
  xmlns="http://www.ibm.com/xmlns/prod/streams/spl/operator" 
  xmlns:cmn="http://www.ibm.com/xmlns/prod/streams/spl/common" 
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xsi:schemaLocation="http://www.ibm.com/xmlns/prod/streams/spl/operator operatorModel.xsd">
  <cppOperatorModel>
    <context>
      <description>
      The WatsonSTT operator is designed to ingest audio data in the form of a file (.wav, .mp3 etc.)
      or RAW audio and then transcribe that audio into text via the 
      IBM Watson STT (Speech To Text) cloud service. It does that by sending the audio data 
      to the configured Watson STT service running in the IBM public cloud or in the 
      IBM Cloud Pak for Data (CP4D) via the Websocket interface. It then outputs transcriptions of 
      speech in the form of utterances or in full text as configured. An utterance is a 
      group of transcribed words meant to approximate a sentence. Audio data must be in 16-bit 
      little endian, mono format. For the Telephony model and configurations, the audio must 
      have an 8 kHz sampling rate. For the Broadband model and configurations, the audio must 
      have a 16 kHz sampling rate. The data can be provided as a .wav file or as 
      RAW uncompressed PCM audio. Here is a sample ffmpeg command to convert a .wav file 
      to the correct telephony format (use -ar 16000 for broadband): 
      
      \$ ffmpeg -i MyFile.wav -ac 1 -ar 8000 MyNewFile.wav
      
      This operator must be configured with a Websocket URL, a Watson STT authentication token and
      a base language model (see in parameter section).
      This operator may also be customized with many other optional parameters including 
      custom patch files and appropriate custom patch weights.
      
      The operator parameter `sttResultMode` specifies what type of STT result is needed:
        * partial: to get partial utterances,
        * final to get completed/final utterance,
        * complete (default) to get the full text after transcribing the entire audio.
      The setting of this this parameter influences the validity of output functions and parameters. 
      
      Requirements: 
      * Intel RHEL6 or RHEL7 hosts installed with IBM Streams. 
      
      **Note:** Multiple invocations of this operator can be fused to make 
      an efficient use of the available pool of CPU cores.
      
      See the samples folder inside this toolkit for working examples that show how to use this operator.
      
      For a detailed documentation about the operator design, usage patterns and in-depth technical
      details, please refer to the official STT Gateway toolkit documentation available at this URL:
      
      [https://ibmstreams.github.io/streamsx.sttgateway]
      </description>

      <iconUri size="16">watsonstt_16.gif</iconUri>
      <iconUri size="32">watsonstt_32.gif</iconUri>

      <metrics>
        <metric>
          <name>sttResultMode</name>
          <description>STT result mode currently in effect for a given operator instance.</description>
          <kind>Gauge</kind>
        </metric>
        
        <metric>
          <name>nWebsocketConnectionAttempts</name>
          <description>The cumulative number of STT service Websocket connection attempts made by this operator instance.</description>
          <kind>Counter</kind>
        </metric>

        <metric>
          <name>nWebsocketConnectionAttemptsFailed</name>
          <description>The cumulative number of failed STT service Websocket connection attempts made by this operator instance.</description>
          <kind>Counter</kind>
        </metric>

        <metric>
          <name>nWebsocketConnectionAttemptsCurrent</name>
          <description>Number of STT service Websocket connection attempts made by this operator instance for the current connection. The value is reset to zero when a connection attempt succeeds.</description>
          <kind>Gauge</kind>
        </metric>
        
        <metric>
          <name>nFullAudioConversationsReceived</name>
          <description>
          Number of full audio conversations received for transcription by this operator instance.
          
          *NOTE:* This metric is only updated if parameter `sttLiveMetricsUpdateNeeded` is true.
          </description>
          <kind>Counter</kind>
        </metric>
        
        <metric>
          <name>nFullAudioConversationsTranscribed</name>
          <description>
          Number of full audio conversations transcribed by this operator instance.
          
          *NOTE:* This metric is only updated if parameter `sttLiveMetricsUpdateNeeded` is true.
          </description>
          <kind>Counter</kind>
        </metric>

        <metric>
          <name>nFullAudioConversationsFailed</name>
          <description>
          Number of full audio conversations failures by this operator instance.
          
          *NOTE:* This metric is only updated if parameter `sttLiveMetricsUpdateNeeded` is true.
          </description>
          <kind>Counter</kind>
        </metric>

        <metric>
          <name>wsConnectionState</name>
          <description>
          The state of the websocket connection:
          
          0=idle: initial idle state
          1=start: start a new connection
          2=connecting: trying to connect to stt
          3=open: connection is opened
          4=listening: listening received
          5=error: error received during transcription
          6=closed: connection has closed
          7=failed: connection has failed
          8=crashed: Error was caught in ws_init tread
          </description>
          <kind>Gauge</kind>
        </metric>

        <metric>
          <name>nAudioBytesSend</name>
          <description>
          The amount of audio samples sent to the stt service in bytes.
          
          *NOTE:* This metric is only updated if parameter `sttLiveMetricsUpdateNeeded` is true.
          </description>
          <kind>Counter</kind>
        </metric>
      </metrics>
      
      <customLiterals>
        <enumeration>
          <name>SttResultMode</name>
          <value>partial</value>
          <value>final</value>
          <value>complete</value>
        </enumeration>
      </customLiterals>
      
      <customOutputFunctions>
        <customOutputFunction>
          <name>STTGatewayFunctions</name>
          <function>
            <description>
            The default function for output attributes. This function assigns the output attribute to the value of the 
            input attribute with the same name.
            </description>
            <prototype><![CDATA[<any T> T AsIs(T)]]></prototype> 
          </function>
          <function>
            <description>
            Returns an int32 number indicating the utterance number. 
            
            **Note:** This function is not available if `sttResult` mode equals `complete`.
            </description>
            <prototype><![CDATA[int32 getUtteranceNumber()]]></prototype>
          </function>
          <function>
            <description>Returns the transcription of audio in the form of a single utterance.</description>
            <prototype><![CDATA[rstring getUtteranceText()]]></prototype>
          </function>
          <function>
            <description>
            Returns a boolean value to indicate if this is an interim partial utterance or a finalized utterance.
            
            **Note:** This function is not available if `sttResult` mode equals `complete`.
            </description>
            <prototype><![CDATA[boolean isFinalizedUtterance()]]></prototype>
          </function>
          <function>
            <description>
            Returns a float32 confidence value for an interim partial utterance or for a finalized utterance or for the full text. 
            
            **Note:** This function is not available if `sttResult` mode equals `complete`.
            </description>
            <prototype><![CDATA[float32 getConfidence()]]></prototype>
          </function>
          <function>
            <description>Returns the Watson STT error message if any.</description>
            <prototype><![CDATA[rstring getSTTErrorMessage()]]></prototype>
          </function>
          <function>
            <description>
            Returns a boolean value to indicate whether the full transcription/conversation is completed. 
            
            **Note:** This function is not available if `sttResult` mode equals `complete`.
            </description>
            <prototype><![CDATA[boolean isTranscriptionCompleted()]]></prototype>
          </function>
          <function>
            <description>
            Returns a list of n-best alternative hypotheses for an utterance result. 
            List will have the very best guess first followed by the next best ones in that order. 
            
            **Note:** This function is not available if `sttResult` mode equals `complete`.
            </description>
            <prototype><![CDATA[list<rstring> getUtteranceAlternatives()]]></prototype>
          </function>
          <function>
            <description>
            Returns a nested list of word alternatives (Confusion Networks). 
            
            **Note:** This function is not available if `sttResult` mode equals `complete`.
            </description>
            <prototype><![CDATA[list<list<rstring>> getWordAlternatives()]]></prototype>
          </function>
          <function>
            <description>
            Returns a nested list of word alternatives confidences (Confusion Networks). 
            
            **Note:** This function is not available if `sttResult` mode equals `complete`.
            </description>
            <prototype><![CDATA[list<list<float64>> getWordAlternativesConfidences()]]></prototype>
          </function>
          <function>
            <description>
            Returns a list of word alternatives start times (Confusion Networks). 
            
            **Note:** This function is not available if `sttResult` mode equals `complete`.
            </description>
            <prototype><![CDATA[list<float64> getWordAlternativesStartTimes()]]></prototype>
          </function>
          <function>
            <description>
            Returns a list of word alternatives end times (Confusion Networks). 
            
            **Note:** This function is not available if `sttResult` mode equals `complete`.
            </description>
            <prototype><![CDATA[list<float64> getWordAlternativesEndTimes()]]></prototype>
          </function>
          <function>
            <description>
            Returns a list of words in an utterance result. 
            
            **Note:** This function is not available if `sttResult` mode equals `complete`.
            </description>
            <prototype><![CDATA[list<rstring> getUtteranceWords()]]></prototype>
          </function>
          <function>
            <description>
            Returns a list of confidences of the words in an utterance result. 
            
            **Note:** This function is not available if `sttResult` mode equals `complete`.
            </description>
            <prototype><![CDATA[list<float64> getUtteranceWordsConfidences()]]></prototype>
          </function>
          <function>
            <description>
            Returns a list of start times of the words in an utterance result relative to the start of the audio. 
            
            **Note:** This function is not available if `sttResult` mode equals `complete`.
            </description>
            <prototype><![CDATA[list<float64> getUtteranceWordsStartTimes()]]></prototype>
          </function>
          <function>
            <description>
            Returns a list of end times of the words in an utterance result relative to the start of the audio. 
            
            **Note:** This function is not available if `sttResult` mode equals `complete`.
            </description>
            <prototype><![CDATA[list<float64> getUtteranceWordsEndTimes()]]></prototype>
          </function>
          <function>
            <description>
            Returns the start time of an utterance relative to the start of the audio. 
            
            **Note:** This function is not available if `sttResult` mode equals `complete`.
            </description>
            <prototype><![CDATA[float64 getUtteranceStartTime()]]></prototype>
          </function>
          <function>
            <description>
            Returns the end time of an utterance relative to the start of the audio. 
            
            **Note:** This function is not available if `sttResult` mode equals `complete`.
            </description>
            <prototype><![CDATA[float64 getUtteranceEndTime()]]></prototype>
          </function>
          <function>
            <description>
            Returns a list of speaker ids for the individual words in an utterance result. 
            
            **Note:** This function is not available if `sttResult` mode equals `complete`.
            </description>
            <prototype><![CDATA[list<int32> getUtteranceWordsSpeakers()]]></prototype>
          </function>
          <function>
            <description>
            Returns a list of confidences in identifying the speakers of the individual words in an utterance result. 
            
            **Note:** This function is not available if `sttResult` mode equals `complete`.
            </description>
            <prototype><![CDATA[list<float64> getUtteranceWordsSpeakersConfidences()]]></prototype>
          </function>
          <function>
            <description>
            Returns the STT keywords spotting results as a map of key/value pairs. Read this toolkit's documentation to learn about the map contents. 
            
            **Note:** This function is not available if `sttResult` mode equals `complete`.
            </description>
            <prototype><![CDATA[map<rstring, list<map<rstring, float64>>> getKeywordsSpottingResults()]]></prototype>
          </function>
        </customOutputFunction>
      </customOutputFunctions>
      
      <libraryDependencies>
      
        <library>
          <cmn:description>Implementation library</cmn:description>
          <cmn:managedLibrary>
            <cmn:includePath>../../impl/include</cmn:includePath>
          </cmn:managedLibrary>
        </library>
        
        <library>
          <cmn:description>Boost Library common/Websocket include and Boost system</cmn:description>
          <cmn:managedLibrary>
            <cmn:lib>boost_system</cmn:lib>
            <cmn:libPath>../../lib</cmn:libPath>
            <cmn:includePath>../../include</cmn:includePath>
          </cmn:managedLibrary>
        </library>
         
        <library>
          <cmn:description>Boost Library chrono</cmn:description>
          <cmn:managedLibrary>
            <cmn:lib>boost_chrono</cmn:lib>
            <cmn:libPath>../../lib</cmn:libPath>
          </cmn:managedLibrary>
        </library>
                
        <library>
          <cmn:description>Boost Library random</cmn:description>
          <cmn:managedLibrary>
            <cmn:lib>boost_random</cmn:lib>
            <cmn:libPath>../../lib</cmn:libPath>
          </cmn:managedLibrary>
        </library>

      </libraryDependencies>
      
      <providesSingleThreadedContext>Never</providesSingleThreadedContext>
    </context>  
    <parameters>
      <allowAny>false</allowAny>
      <parameter>
        <name>uri</name>
        <description>
        This parameter specifies the Watson STT Websocket service URI. 
        see: [https://cloud.ibm.com/docs/services/speech-to-text?topic=speech-to-text-websockets#WSopen] 
        </description>
        <optional>false</optional>
        <rewriteAllowed>true</rewriteAllowed>
        <expressionMode>AttributeFree</expressionMode>
        <type>rstring</type>
        <cardinality>1</cardinality>
      </parameter>

      <parameter>
        <name>baseLanguageModel</name>
        <description>
        This parameter specifies the name of the Watson STT base language model that should be used. 
        see: [https://cloud.ibm.com/docs/services/speech-to-text?topic=speech-to-text-input#models] 
        </description>
        <optional>false</optional>
        <rewriteAllowed>true</rewriteAllowed>
        <expressionMode>AttributeFree</expressionMode>
        <type>rstring</type>
        <cardinality>1</cardinality>
      </parameter>

      <parameter>
        <name>contentType</name>
        <description>This parameter specifies the content type to be used for transcription. (Default is audio/wav)</description>
        <optional>true</optional>
        <rewriteAllowed>true</rewriteAllowed>
        <expressionMode>AttributeFree</expressionMode>
        <type>rstring</type>
        <cardinality>1</cardinality>
      </parameter> 

      <parameter>
        <name>sttResultMode</name>
        <description>
        This parameter specifies what type of STT result is needed: `partial`: to get partial utterances, `final`: to get completed/final utterance, 
        `complete`: (default) to get the full text after transcribing the entire audio. The setting of this If this parameter 
        influences the validity of output functions.

        In sttResultMode `complete` the following parameters are not allowed:
        `maxUtteranceAlternatives`, `wordAlternativesThreshold`, `keywordsSpottingThreshold`, `keywordsToBeSpotted`, 
        
        In sttResultMode `complete` the following output functions are not allowed: 
        `getUtteranceNumber()`, `isFinalizedUtterance()`, `getConfidence()`, `isTranscriptionCompleted()`, `getUtteranceAlternatives()`, 
        `getWordAlternatives()`, `getWordAlternativesConfidences()`, `getWordAlternativesStartTimes()`, `getWordAlternativesEndTimes()`, 
        `getUtteranceWords()`, `getUtteranceWordsConfidences()`, `getUtteranceWordsStartTimes()`, `getUtteranceWordsEndTimes()`, 
        `getUtteranceStartTime()`, `getUtteranceEndTime()`, `getUtteranceWordsSpeakers()`, `getUtteranceWordsSpeakersConfidences()`, 
        `getKeywordsSpottingResults()`
        </description>
        <optional>true</optional>
        <rewriteAllowed>false</rewriteAllowed>
        <expressionMode>CustomLiteral</expressionMode>
        <type>SttResultMode</type>
        <cardinality>1</cardinality>
      </parameter> 
      
      <parameter>
        <name>sttRequestLogging</name>
        <description>
        Indicates whether IBM can use data that is sent over the connection to improve the service for future users. 
        Specify false to prevent IBM from accessing the logged data. (Default is false)
        see: [https://cloud.ibm.com/docs/services/speech-to-text?topic=speech-to-text-input#logging] 
        </description>
        <optional>true</optional>
        <rewriteAllowed>true</rewriteAllowed>
        <expressionMode>AttributeFree</expressionMode>
        <type>boolean</type>
        <cardinality>1</cardinality>
      </parameter>

      <parameter>
        <name>baseModelVersion</name>
        <description>
        This parameter specifies a particular base model version to be used for transcription. (Default is an empty string)
        
        The parameter may point to a specific version of the base model if needed.
        e-g: "en-US_NarrowbandModel.v07-06082016.06202016"
        see: [https://cloud.ibm.com/docs/services/speech-to-text?topic=speech-to-text-input#version] 
        </description>
        <optional>true</optional>
        <rewriteAllowed>true</rewriteAllowed>
        <expressionMode>AttributeFree</expressionMode>
        <type>rstring</type>
        <cardinality>1</cardinality>
      </parameter>

      <parameter>
        <name>customizationId</name>
        <description>
        This parameter specifies a custom language model to be used for transcription. 
        see: [https://cloud.ibm.com/docs/services/speech-to-text?topic=speech-to-text-input#custom] 
        (Default is an empty string)
        </description>
        <optional>true</optional>
        <rewriteAllowed>true</rewriteAllowed>
        <expressionMode>AttributeFree</expressionMode>
        <type>rstring</type>
        <cardinality>1</cardinality>
      </parameter>

      <parameter>
        <name>customizationWeight</name>
        <description>This parameter specifies a relative weight for a custom language model as a float64 between 0.0 to 1.0 (Default is 0.0)</description>
        <optional>true</optional>
        <rewriteAllowed>true</rewriteAllowed>
        <expressionMode>AttributeFree</expressionMode>
        <type>float64</type>
        <cardinality>1</cardinality>
      </parameter>  
        
      <parameter>
        <name>acousticCustomizationId</name>
        <description>This parameter specifies a custom acoustic model to be used for transcription. (Default is an empty string)</description>
        <optional>true</optional>
        <rewriteAllowed>true</rewriteAllowed>
        <expressionMode>AttributeFree</expressionMode>
        <type>rstring</type>
        <cardinality>1</cardinality>
      </parameter> 

      <parameter>
        <name>filterProfanity</name>
        <description>
        This parameter indicates whether profanity should be filtered from a transcript. (Default is false) 
        see: [https://cloud.ibm.com/docs/services/speech-to-text?topic=speech-to-text-output#profanity_filter] 
        </description>
        <optional>true</optional>
        <rewriteAllowed>true</rewriteAllowed>
        <expressionMode>AttributeFree</expressionMode>
        <type>boolean</type>
        <cardinality>1</cardinality>
      </parameter>

      <parameter>
        <name>sttJsonResponseDebugging</name>
        <description>This parameter is used for debugging the STT JSON response message. Mostly for IBM internal use. (Default is false)</description>
        <optional>true</optional>
        <rewriteAllowed>true</rewriteAllowed>
        <expressionMode>AttributeFree</expressionMode>
        <type>boolean</type>
        <cardinality>1</cardinality>
      </parameter>
      
      <parameter>
        <name>maxUtteranceAlternatives</name>
        <description>
        This parameter indicates the required number of n-best alternative hypotheses for the transcription results. (Default is 1)
        see: [https://cloud.ibm.com/docs/services/speech-to-text?topic=speech-to-text-output#max_alternatives] 
        
        **Note:** This parameter is not valid if `sttResultMode` equals `complete`.
        </description>
        <optional>true</optional>
        <rewriteAllowed>true</rewriteAllowed>
        <expressionMode>AttributeFree</expressionMode>
        <type>int32</type>
        <cardinality>1</cardinality>
      </parameter>

      <parameter>
        <name>wordAlternativesThreshold</name>
        <description>
        This parameter controls the density of the word alternatives results (a.k.a. Confusion Networks). A value of 0.0 
        disables this feature. Valid value must be less than 1.0 (Default is 0.0)
        see: [https://cloud.ibm.com/docs/services/speech-to-text?topic=speech-to-text-output#word_alternatives] 
        
        **Note:** This parameter is not valid if `sttResultMode` equals `complete`.
        </description>
        <optional>true</optional>
        <rewriteAllowed>true</rewriteAllowed>
        <expressionMode>AttributeFree</expressionMode>
        <type>float64</type>
        <cardinality>1</cardinality>
      </parameter>

      <parameter>
        <name>smartFormattingNeeded</name>
        <description>
        This parameter indicates whether to convert date, time, phone numbers, currency values, email and URLs into conventional representations. (Default is false)
        see: [https://cloud.ibm.com/docs/services/speech-to-text?topic=speech-to-text-output#smart_formatting] 
        </description>
        <optional>true</optional>
        <rewriteAllowed>true</rewriteAllowed>
        <expressionMode>AttributeFree</expressionMode>
        <type>boolean</type>
        <cardinality>1</cardinality>
      </parameter>

      <parameter>
        <name>keywordsSpottingThreshold</name>
        <description>
        This parameter specifies the minimum confidence level that the STT service must have for an utterance word to 
        match a given keyword. A value of 0.0 disables this feature. Valid value must be less than 1.0. (Default is 0.0)
        see: [https://cloud.ibm.com/docs/services/speech-to-text?topic=speech-to-text-output#keyword_spotting] 
        
        **Note:** This parameter is not valid if `sttResultMode` equals `complete`.
        </description>
        <optional>true</optional>
        <rewriteAllowed>true</rewriteAllowed>
        <expressionMode>AttributeFree</expressionMode>
        <type>float64</type>
        <cardinality>1</cardinality>
      </parameter>

      <parameter>
        <name>keywordsToBeSpotted</name>
        <description>
        This parameter specifies a list (array) of strings to be spotted. (Default is an empty list)
        
        **Note:** This parameter is not valid if `sttResultMode` equals `complete`.
        </description>
        <optional>true</optional>
        <rewriteAllowed>true</rewriteAllowed>
        <expressionMode>AttributeFree</expressionMode>
        <type>list&lt;rstring&gt;</type>
        <cardinality>1</cardinality>
      </parameter>

      <parameter>
        <name>websocketLoggingNeeded</name>
        <description>This parameter specifies whether logging is needed from the Websocket library. (Default is false)</description>
        <optional>true</optional>
        <rewriteAllowed>true</rewriteAllowed>
        <expressionMode>AttributeFree</expressionMode>
        <type>boolean</type>
        <cardinality>1</cardinality>
      </parameter>

      <parameter>
        <name>cpuYieldTimeInAudioSenderThread</name>
        <description>This parameter specifies the CPU yield time (in seconds) needed inside the audio sender thread's tight loop spinning to look for new audio data to be sent to the STT service. It should be >= 0.0 (Default is 0.001 i.e. 1 millisecond)</description>
        <optional>true</optional>
        <rewriteAllowed>true</rewriteAllowed>
        <expressionMode>AttributeFree</expressionMode>
        <type>float64</type>
        <cardinality>1</cardinality>
      </parameter>
      
      <parameter>
        <name>maxConnectionRetryDelay</name>
        <description>
        The maximum wait time in seconds before a connection re-try is made. The re-try 
        delay of connection to the STT service increases exponentially starting from 2 seconds but not exceeding 
        'maxConnectionRetryDelay'. It must be greater 1.0 (Default is 60.0)
        </description>
        <optional>true</optional>
        <rewriteAllowed>true</rewriteAllowed>
        <expressionMode>AttributeFree</expressionMode>
        <type>float64</type>
        <cardinality>1</cardinality>
      </parameter>

      <parameter>
        <name>sttLiveMetricsUpdateNeeded</name>
        <description>This parameter specifies whether live update for this operator's metrics `nFullAudioConversationsReceived` and `nFullAudioConversationsTranscribed` is needed. (Default is true)</description>
        <optional>true</optional>
        <rewriteAllowed>true</rewriteAllowed>
        <expressionMode>AttributeFree</expressionMode>
        <type>boolean</type>
        <cardinality>1</cardinality>
      </parameter>

    </parameters>
    <inputPorts>
      <inputPortSet>
        <description>
        This port brings the audio data into this operator for transcription.
        
        Attributes on this input port:
        * **speech** (required, rstring/blob) - In the case of file based input (.wav, .mp3 etc. for batch workload), the expected value will be an absolute path of a file as an rstring. In the case of RAW audio data (received from a network switch for real-time workload), the expected input is of type blob.
        
        A window punctuation marker is used to mark the end of an conversation. When the end of conversation is encountered,
        the STT engine delivers all results of the current conversation and flushes all buffers.
        All the extra input attributes will be forwarded if matching output attributes are found.
        </description>
        <tupleMutationAllowed>false</tupleMutationAllowed>
        <windowingMode>NonWindowed</windowingMode>
        <windowPunctuationInputMode>Expecting</windowPunctuationInputMode>
        <cardinality>1</cardinality>
        <optional>false</optional>
      </inputPortSet>
      
      <inputPortSet>
        <description>
        This port brings an unexpired IAM access token (generated by using your 
        service instance's API key) into this operator that is needed to access the Watson STT service. This input port 
        should be used in a different thread than port 0.
        
        Attributes on this input port: 
        * **access_token** (required, rstring) - An rstring access token required for securing the access to the STT service. 
        
        All the extra attributes found in this input port will be ignored.
        </description>
        <tupleMutationAllowed>false</tupleMutationAllowed>
        <windowingMode>NonWindowed</windowingMode>
        <windowPunctuationInputMode>Oblivious</windowPunctuationInputMode>
          <controlPort>true</controlPort>
          <cardinality>1</cardinality>
          <optional>false</optional>
      </inputPortSet>
    </inputPorts>
    <outputPorts>
      <outputPortSet>
        <description>
        This port produces the output tuples that carry the result of the speech to text transcription.
        
        An output tuple is created for every utterance that is observed from the incoming audio data. 
        An utterance is a group of transcribed words meant to approximate a sentence. 
        This means there is a one to many relationship between an incoming tuple and outgoing tuples 
        (i.e. a single .wav file may result in 30 output utterances).
        Intermediate utterances are sent out on this output port only when the sttResultMode
        operator parameter is set to a value of either 1 or 2. If it is set to 3, then only the
        fully transcribed text for the entire audio data will be sent on this output port after
        the given audio is completely transcribed. The port emits a window punctuation marker when a conversation 
        has finished.
        **There are multiple available output functions**, and output attributes can also be 
        assigned values with any SPL expression that evaluates to the proper type.
        </description>
        <expressionMode>Expression</expressionMode>
        <autoAssignment>true</autoAssignment>
        <completeAssignment>false</completeAssignment>
        <rewriteAllowed>true</rewriteAllowed>
        <outputFunctions>
            <default>AsIs</default>
            <type>STTGatewayFunctions</type>
        </outputFunctions> 
        <windowPunctuationOutputMode>Generating</windowPunctuationOutputMode>
        <finalPunctuationPortScope>
        </finalPunctuationPortScope>
        <tupleMutationAllowed>true</tupleMutationAllowed>
        <cardinality>1</cardinality>
        <optional>false</optional>
      </outputPortSet>
    </outputPorts>
  </cppOperatorModel>
</operatorModel>
